{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The aim of this notebook is to load, analyze and preprocess raw data  (clean if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_json(\"../data/raw/Graduate - HEADLINES dataset (2019-06).json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic information about data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26709 entries, 0 to 26708\n",
      "Data columns (total 2 columns):\n",
      "headline        26709 non-null object\n",
      "is_sarcastic    26709 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 417.4+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data to tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = raw_data[\"headline\"]\n",
    "result = raw_data[\"is_sarcastic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break words into tokens, add CLS--start and SEP--end tokens, convert tokens into unique id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers as ppb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = sentence.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = pd.concat((tokenized, result), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data.to_json(\"../data/interim/Graduate - HEADLINES dataset (2019-06)_TOKENIZED.json\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create padded matrix with the same number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for row in tokenized.values:\n",
    "    if len(row) > max_len:\n",
    "        max_len = len(row)\n",
    "\n",
    "padded = np.array([row + [0] * (max_len - len(row)) for row in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26709, 66)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data packages, this step is realized in google cloud instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rows = padded.shape[0]\n",
    "\n",
    "size_of_packages = 500\n",
    "number_of_packages = round(number_of_rows / size_of_packages, 0) + 1\n",
    "start = 0\n",
    "end = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 54.0\n",
      "500 1000\n",
      "500\n",
      "Epoch: 2 / 54.0\n",
      "1000 1500\n",
      "500\n",
      "Epoch: 3 / 54.0\n",
      "1500 2000\n",
      "500\n",
      "Epoch: 4 / 54.0\n",
      "2000 2500\n",
      "500\n",
      "Epoch: 5 / 54.0\n",
      "2500 3000\n",
      "500\n",
      "Epoch: 6 / 54.0\n",
      "3000 3500\n",
      "500\n",
      "Epoch: 7 / 54.0\n",
      "3500 4000\n",
      "500\n",
      "Epoch: 8 / 54.0\n",
      "4000 4500\n",
      "500\n",
      "Epoch: 9 / 54.0\n",
      "4500 5000\n",
      "500\n",
      "Epoch: 10 / 54.0\n",
      "5000 5500\n",
      "500\n",
      "Epoch: 11 / 54.0\n",
      "5500 6000\n",
      "500\n",
      "Epoch: 12 / 54.0\n",
      "6000 6500\n",
      "500\n",
      "Epoch: 13 / 54.0\n",
      "6500 7000\n",
      "500\n",
      "Epoch: 14 / 54.0\n",
      "7000 7500\n",
      "500\n",
      "Epoch: 15 / 54.0\n",
      "7500 8000\n",
      "500\n",
      "Epoch: 16 / 54.0\n",
      "8000 8500\n",
      "500\n",
      "Epoch: 17 / 54.0\n",
      "8500 9000\n",
      "500\n",
      "Epoch: 18 / 54.0\n",
      "9000 9500\n",
      "500\n",
      "Epoch: 19 / 54.0\n",
      "9500 10000\n",
      "500\n",
      "Epoch: 20 / 54.0\n",
      "10000 10500\n",
      "500\n",
      "Epoch: 21 / 54.0\n",
      "10500 11000\n",
      "500\n",
      "Epoch: 22 / 54.0\n",
      "11000 11500\n",
      "500\n",
      "Epoch: 23 / 54.0\n",
      "11500 12000\n",
      "500\n",
      "Epoch: 24 / 54.0\n",
      "12000 12500\n",
      "500\n",
      "Epoch: 25 / 54.0\n",
      "12500 13000\n",
      "500\n",
      "Epoch: 26 / 54.0\n",
      "13000 13500\n",
      "500\n",
      "Epoch: 27 / 54.0\n",
      "13500 14000\n",
      "500\n",
      "Epoch: 28 / 54.0\n",
      "14000 14500\n",
      "500\n",
      "Epoch: 29 / 54.0\n",
      "14500 15000\n",
      "500\n",
      "Epoch: 30 / 54.0\n",
      "15000 15500\n",
      "500\n",
      "Epoch: 31 / 54.0\n",
      "15500 16000\n",
      "500\n",
      "Epoch: 32 / 54.0\n",
      "16000 16500\n",
      "500\n",
      "Epoch: 33 / 54.0\n",
      "16500 17000\n",
      "500\n",
      "Epoch: 34 / 54.0\n",
      "17000 17500\n",
      "500\n",
      "Epoch: 35 / 54.0\n",
      "17500 18000\n",
      "500\n",
      "Epoch: 36 / 54.0\n",
      "18000 18500\n",
      "500\n",
      "Epoch: 37 / 54.0\n",
      "18500 19000\n",
      "500\n",
      "Epoch: 38 / 54.0\n",
      "19000 19500\n",
      "500\n",
      "Epoch: 39 / 54.0\n",
      "19500 20000\n",
      "500\n",
      "Epoch: 40 / 54.0\n",
      "20000 20500\n",
      "500\n",
      "Epoch: 41 / 54.0\n",
      "20500 21000\n",
      "500\n",
      "Epoch: 42 / 54.0\n",
      "21000 21500\n",
      "500\n",
      "Epoch: 43 / 54.0\n",
      "21500 22000\n",
      "500\n",
      "Epoch: 44 / 54.0\n",
      "22000 22500\n",
      "500\n",
      "Epoch: 45 / 54.0\n",
      "22500 23000\n",
      "500\n",
      "Epoch: 46 / 54.0\n",
      "23000 23500\n",
      "500\n",
      "Epoch: 47 / 54.0\n",
      "23500 24000\n",
      "500\n",
      "Epoch: 48 / 54.0\n",
      "24000 24500\n",
      "500\n",
      "Epoch: 49 / 54.0\n",
      "24500 25000\n",
      "500\n",
      "Epoch: 50 / 54.0\n",
      "25000 25500\n",
      "500\n",
      "Epoch: 51 / 54.0\n",
      "25500 26000\n",
      "500\n",
      "Epoch: 52 / 54.0\n",
      "26000 26500\n",
      "500\n",
      "Epoch: 53 / 54.0\n",
      "26500 27000\n",
      "500\n",
      "Epoch: 54 / 54.0\n",
      "26709 27209\n",
      "209\n"
     ]
    }
   ],
   "source": [
    "for pack in range(int(number_of_packages)):\n",
    "    \n",
    "    print(\"Epoch: {} / {}\".format(pack+1, number_of_packages))\n",
    "    \n",
    "    if number_of_rows < size_of_packages:\n",
    "        size_of_packages = number_of_rows\n",
    "    \n",
    "    padded_set = padded[start: end, :]\n",
    "    labels_set = np.array(result[start: end]).reshape(-1, 1)\n",
    "    \n",
    "    input_ids = torch.tensor(np.array(padded_set))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids)\n",
    "        \n",
    "    features = last_hidden_states[0][:,0,:].numpy()\n",
    "    ready_pack = np.concatenate((features, labels_set), axis = 1)\n",
    "    np.save(\"../data/interim/distilBERT_output/pack_{}.npy\".format(pack), ready_pack)\n",
    "    \n",
    "    number_of_rows = number_of_rows - size_of_packages\n",
    "    start += size_of_packages\n",
    "    end += size_of_packages\n",
    "    \n",
    "    print(start, end)\n",
    "    print(size_of_packages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
